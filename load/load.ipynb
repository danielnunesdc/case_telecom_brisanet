{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcf50058-88ff-47f0-8a9c-7e444bc48400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Optional, Dict, List\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d79a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eecebc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec41cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Dataset já existe: automacoes-481202.case_telecom\n",
      "[ENVIANDO] ../output/base_clientes_tratada.csv -> automacoes-481202.case_telecom.base_clientes\n",
      "[OK] Carregado: automacoes-481202.case_telecom.base_clientes | linhas: 10000 | colunas: 15\n",
      "[ENVIANDO] ../output/base_produtos_tratada.csv -> automacoes-481202.case_telecom.base_produtos\n",
      "[OK] Carregado: automacoes-481202.case_telecom.base_produtos | linhas: 6 | colunas: 2\n",
      "[ENVIANDO] ../output/base_vendas_tratada.csv -> automacoes-481202.case_telecom.base_vendas\n",
      "[OK] Carregado: automacoes-481202.case_telecom.base_vendas | linhas: 5000 | colunas: 8\n",
      "[ENVIANDO] ../output/base_info_vendas_tratada.csv -> automacoes-481202.case_telecom.informacoes_vendas\n",
      "[OK] Carregado: automacoes-481202.case_telecom.informacoes_vendas | linhas: 5000 | colunas: 11\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"automacoes-481202\" \n",
    "DATASET_ID = \"case_telecom\" \n",
    "\n",
    "CSV_DELIMITER = \",\" \n",
    "\n",
    "SKIP_LEADING_ROWS = 1\n",
    "\n",
    "FILES_TO_TABLES: List[Dict[str, str]] = [\n",
    "    {\n",
    "        \"path\": \"../output/base_clientes_tratada.csv\",\n",
    "        \"table\": \"base_clientes\",\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"../output/base_produtos_tratada.csv\",\n",
    "        \"table\": \"base_produtos\",\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"../output/base_vendas_tratada.csv\",\n",
    "        \"table\": \"base_vendas\",\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"../output/base_info_vendas_tratada.csv\",\n",
    "        \"table\": \"informacoes_vendas\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Comportamento de escrita:\n",
    "# - WRITE_TRUNCATE: substitui a tabela toda a cada carga\n",
    "# - WRITE_APPEND: acrescenta registros (use com cuidado)\n",
    "WRITE_DISPOSITION = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "CREATE_DISPOSITION = bigquery.CreateDisposition.CREATE_IF_NEEDED\n",
    "\n",
    "\n",
    "def get_bq_client(project_id: str) -> bigquery.Client:\n",
    "\n",
    "    return bigquery.Client(project=project_id)\n",
    "\n",
    "\n",
    "def ensure_dataset(client: bigquery.Client, project_id: str, dataset_id: str, location: str = \"US\") -> None:\n",
    "\n",
    "    dataset_ref = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
    "    dataset_ref.location = location\n",
    "\n",
    "    try:\n",
    "        client.get_dataset(dataset_ref)\n",
    "        print(f\"[OK] Dataset já existe: {project_id}.{dataset_id}\")\n",
    "    except Exception:\n",
    "        client.create_dataset(dataset_ref, exists_ok=True)\n",
    "        print(f\"[CRIADO] Dataset criado: {project_id}.{dataset_id} (location={location})\")\n",
    "\n",
    "\n",
    "def load_csv_to_table(\n",
    "    client: bigquery.Client,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    table_name: str,\n",
    "    file_path: str,\n",
    "    field_delimiter: str = \";\",\n",
    "    skip_leading_rows: int = 1,\n",
    "    write_disposition: str = bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    create_disposition: str = bigquery.CreateDisposition.CREATE_IF_NEEDED,\n",
    "    autodetect_schema: bool = True,\n",
    ") -> None:\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        field_delimiter=field_delimiter,\n",
    "        skip_leading_rows=skip_leading_rows,\n",
    "        autodetect=autodetect_schema,\n",
    "        write_disposition=write_disposition,\n",
    "        create_disposition=create_disposition,\n",
    "        allow_quoted_newlines=True,  # tolerância a quebras de linha em campos com aspas\n",
    "    )\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        load_job = client.load_table_from_file(\n",
    "            f,\n",
    "            destination=table_id,\n",
    "            job_config=job_config,\n",
    "        )\n",
    "\n",
    "    print(f\"[ENVIANDO] {file_path} -> {table_id}\")\n",
    "    load_job.result()  # espera finalizar\n",
    "\n",
    "    table = client.get_table(table_id)\n",
    "    print(f\"[OK] Carregado: {table_id} | linhas: {table.num_rows} | colunas: {len(table.schema)}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    client = get_bq_client(PROJECT_ID)\n",
    "\n",
    "    # 2) Dataset (cria se não existir)\n",
    "    # Ajuste location se necessário.\n",
    "    ensure_dataset(client, PROJECT_ID, DATASET_ID, location=\"US\")\n",
    "\n",
    "    # 3) Cargas (1 arquivo = 1 tabela)\n",
    "    for item in FILES_TO_TABLES:\n",
    "        file_path = item[\"path\"]\n",
    "        table_name = item[\"table\"]\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"[ERRO] Arquivo não encontrado: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        load_csv_to_table(\n",
    "            client=client,\n",
    "            project_id=PROJECT_ID,\n",
    "            dataset_id=DATASET_ID,\n",
    "            table_name=table_name,\n",
    "            file_path=file_path,\n",
    "            field_delimiter=CSV_DELIMITER,\n",
    "            skip_leading_rows=SKIP_LEADING_ROWS,\n",
    "            write_disposition=WRITE_DISPOSITION,\n",
    "            create_disposition=CREATE_DISPOSITION,\n",
    "            autodetect_schema=True,\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "case-vendas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
